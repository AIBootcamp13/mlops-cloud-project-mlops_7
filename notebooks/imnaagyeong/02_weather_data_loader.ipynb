{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c86372f1b965adb5",
   "metadata": {},
   "source": [
    "# Notebook 기본 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bbee03e090649db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constant 선언\n",
    "\n",
    "# 프로젝트 루트 디렉토리를 식별하기 위한 마커 파일 이름\n",
    "ROOT_MARKER = \"pyproject.toml\"\n",
    "\n",
    "# 한글 표시를 위한 나눔바른고딕 폰트 파일 이름\n",
    "# matplotlib 의 font_manager 에 실제 폰트 파일의 위치를 넣어주어야 한다.\n",
    "KOREAN_FONT_FILE = \"NanumBarunGothic.ttf\"\n",
    "\n",
    "# matplotlib 에서는 font-family 의 이름으로 font 를 설정한다.\n",
    "# 그래서 font 파일 그 자체가 아니라, 그 파일의 family 이름을 적어준다.\n",
    "KOREAN_FONT_FAMILY = \"NanumBarunGothic\"\n",
    "\n",
    "# 참고\n",
    "# Font Family 와 Font File 의 차이는,\n",
    "# Font Family 는 비슷한 디자인 특성을 공유하는 글꼴 그룹을 의미한다.\n",
    "#\n",
    "# 예를 들어 '나눔바른고딕' 폰트 패밀리는 일반(Regular), 굵게(Bold), 기울임(Italic) 등 여러 스타일을 포함할 수 있다.\n",
    "# 반면, 폰트 파일(.ttf, .otf 등)은 이러한 폰트의 하나의 스타일이 저장된 실제 파일이다.\n",
    "#\n",
    "# 이 프로젝트에서는 폰트 용량을 줄이기 위해 일반(Regular) 인 NanumBarunGothic.ttf 만 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93f2746669fe3b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프로젝트 root 를 sys.path 에 추가해서 import 구문을 사용하기 쉽게\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def find_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    pyproject.toml 파일을 기준으로 루트 디렉토리를 찾는다.\n",
    "    :return: Path: 프로젝트 루트 디렉토리 경로\n",
    "    \"\"\"\n",
    "\n",
    "    current_path = Path().resolve()\n",
    "\n",
    "    while current_path != current_path.parent:\n",
    "        if (current_path / ROOT_MARKER).exists():\n",
    "            return current_path\n",
    "\n",
    "        current_path = current_path.parent\n",
    "\n",
    "    raise FileNotFoundError(\"프로젝트 루트 디렉토리를 찾을 수 없습니다.\")\n",
    "\n",
    "\n",
    "ROOT_DIR = find_project_root()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b2102dd84f4bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib 의 한글 font 설정\n",
    "import matplotlib.font_manager as fm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "FONTS_DATA_DIR = ROOT_DIR / \"notebooks\" / \"fonts\"\n",
    "\n",
    "\n",
    "def setup_korean_font():\n",
    "    font_path = FONTS_DATA_DIR / KOREAN_FONT_FILE\n",
    "    fm.fontManager.addfont(font_path)\n",
    "\n",
    "    # 폰트 설정\n",
    "    plt.rcParams[\"font.family\"] = KOREAN_FONT_FAMILY\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "\n",
    "setup_korean_font()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac8d04607dc6327",
   "metadata": {},
   "source": [
    "# 데이터 수집\n",
    "1.\tweather_station_list.csv에 정의된 전체 지점(stnId)을 기준으로 기상청 API에서 날씨 데이터를 수집\n",
    "2.\tJSON 응답 데이터를 DataFrame으로 변환하고, 기존 데이터(weather_raw.csv)가 있다면 병합 \n",
    "3.\t최신 버전으로 weather_raw.csv 덮어쓰기 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135a7c6f3a7571cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "from time import sleep\n",
    "import boto3\n",
    "from botocore.client import Config\n",
    "import math\n",
    "\n",
    "# 환경변수 불러오기\n",
    "WEATHER_API_KEY = os.getenv(\"WEATHER_API_KEY\")\n",
    "NCLOUD_ACCESS_KEY = os.getenv(\"NCLOUD_ACCESS_KEY\")\n",
    "NCLOUD_SECRET_KEY = os.getenv(\"NCLOUD_SECRET_KEY\")\n",
    "NCLOUD_STORAGE_REGION = os.getenv(\"NCLOUD_STORAGE_REGION\")\n",
    "NCLOUD_STORAGE_BUCKET = os.getenv(\"NCLOUD_STORAGE_BUCKET\")\n",
    "NCLOUD_STORAGE_ENDPOINT_URL = os.getenv(\"NCLOUD_STORAGE_ENDPOINT_URL\")\n",
    "\n",
    "# S3 클라이언트 생성\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=NCLOUD_STORAGE_ENDPOINT_URL,\n",
    "    aws_access_key_id=NCLOUD_ACCESS_KEY,\n",
    "    aws_secret_access_key=NCLOUD_SECRET_KEY,\n",
    "    region_name=NCLOUD_STORAGE_REGION,\n",
    "    config=Config(signature_version=\"s3v4\"),\n",
    ")\n",
    "\n",
    "# 데이터 저장 경로\n",
    "DATASETS_DIR = \"datasets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8344e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S3에서 CSV 읽는 함수\n",
    "def read_csv_as_dataframe(s3_key: str) -> pd.DataFrame:\n",
    "    response = s3_client.get_object(Bucket=NCLOUD_STORAGE_BUCKET, Key=s3_key)\n",
    "    return pd.read_csv(response[\"Body\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c55480be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_weather_data_to_s3_with_pagination(\n",
    "    start_date: str,\n",
    "    end_date: str,\n",
    "    station_csv_path: str,\n",
    "    s3_filename: str,\n",
    "):\n",
    "    \"\"\"\n",
    "    전체 지점의 날씨 데이터를 페이지네이션 방식으로 수집하고 S3에 저장 (기존 데이터 병합 없이 덮어쓰기)\n",
    "    \"\"\"\n",
    "    base_url = \"http://apis.data.go.kr/1360000/AsosDalyInfoService/getWthrDataList\"\n",
    "    weather_api_key = os.getenv(\"WEATHER_API_KEY\")\n",
    "\n",
    "    # 1. 전체 지점 목록 불러오기\n",
    "    station_df = pd.read_csv(station_csv_path)\n",
    "    station_ids = station_df[\"stnId\"].dropna().astype(str).unique()\n",
    "\n",
    "    all_data = []\n",
    "\n",
    "    for stn_id in station_ids:\n",
    "        print(f\"\\n📍 지점 {stn_id} 데이터 수집 시작\")\n",
    "        common_params = {\n",
    "            \"serviceKey\": weather_api_key,\n",
    "            \"pageNo\": \"1\",\n",
    "            \"numOfRows\": \"999\",\n",
    "            \"dataType\": \"JSON\",\n",
    "            \"dataCd\": \"ASOS\",\n",
    "            \"dateCd\": \"DAY\",\n",
    "            \"startDt\": start_date,\n",
    "            \"endDt\": end_date,\n",
    "            \"stnIds\": stn_id,\n",
    "        }\n",
    "\n",
    "        # 최대 pageNo 계산\n",
    "        try:\n",
    "            response = requests.get(base_url, params=common_params, timeout=20)\n",
    "            response.raise_for_status()\n",
    "            json_data = response.json()\n",
    "\n",
    "            if 'response' in json_data and 'body' in json_data['response']:\n",
    "                body = json_data['response']['body']\n",
    "                total_count = int(body['totalCount'])\n",
    "                max_page_no = math.ceil(total_count / int(common_params[\"numOfRows\"]))\n",
    "                print(f\"📄 총 페이지 수: {max_page_no}\")\n",
    "            else:\n",
    "                raise ValueError(\"❌ 응답에 'body' 없음 또는 데이터 없음\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ 페이지 수 계산 실패 - 지점 {stn_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # 페이지별 데이터 수집\n",
    "        for page in range(1, max_page_no + 1):\n",
    "            common_params[\"pageNo\"] = str(page)\n",
    "            try:\n",
    "                response = requests.get(base_url, params=common_params, timeout=20)\n",
    "                response.raise_for_status()\n",
    "                items = response.json()['response']['body']['items']['item']\n",
    "                df = pd.DataFrame(items)\n",
    "                df[\"stnId\"] = stn_id\n",
    "                all_data.append(df)\n",
    "                print(f\"✅ {stn_id} - 페이지 {page} 수집 완료\")\n",
    "                sleep(1)\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {stn_id} - 페이지 {page} 수집 실패: {e}\")\n",
    "                continue\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"❌ 데이터 수집 결과가 비어 있습니다. 종료합니다.\")\n",
    "        return\n",
    "\n",
    "    # 데이터 병합\n",
    "    full_df = pd.concat(all_data, ignore_index=True)\n",
    "    print(f\"\\n✅ 전체 데이터 수집 완료. 총 샘플 수: {full_df.shape[0]}\")\n",
    "\n",
    "    # 로컬 CSV 저장\n",
    "    full_df.to_csv(\"weather_fulldata.csv\", index=False)\n",
    "    print(\"✅ 수집한 전체 데이터를 weather_fulldata.csv 파일로 저장했습니다.\")\n",
    "\n",
    "    # # S3 업로드\n",
    "    # csv_buffer = StringIO()\n",
    "    # full_df.to_csv(csv_buffer, index=False)\n",
    "    # s3_key = f\"{DATASETS_DIR}/{s3_filename}\"\n",
    "    # s3_client.put_object(Bucket=NCLOUD_STORAGE_BUCKET, Key=s3_key, Body=csv_buffer.getvalue())\n",
    "    # print(f\"✅ S3 저장 완료: {s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "020fbd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📍 지점 90 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 90 - 페이지 1 수집 완료\n",
      "✅ 90 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 93 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 93 - 페이지 1 수집 완료\n",
      "✅ 93 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 95 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 95 - 페이지 1 수집 완료\n",
      "✅ 95 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 98 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 98 - 페이지 1 수집 완료\n",
      "✅ 98 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 99 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 99 - 페이지 1 수집 완료\n",
      "✅ 99 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 100 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 100 - 페이지 1 수집 완료\n",
      "✅ 100 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 101 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 101 - 페이지 1 수집 완료\n",
      "✅ 101 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 102 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 102 - 페이지 1 수집 완료\n",
      "✅ 102 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 104 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 104 - 페이지 1 수집 완료\n",
      "✅ 104 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 105 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 105 - 페이지 1 수집 완료\n",
      "✅ 105 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 106 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 106 - 페이지 1 수집 완료\n",
      "✅ 106 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 108 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 108 - 페이지 1 수집 완료\n",
      "✅ 108 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 112 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 112 - 페이지 1 수집 완료\n",
      "✅ 112 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 114 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 114 - 페이지 1 수집 완료\n",
      "✅ 114 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 115 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 115 - 페이지 1 수집 완료\n",
      "✅ 115 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 119 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 119 - 페이지 1 수집 완료\n",
      "✅ 119 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 121 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 121 - 페이지 1 수집 완료\n",
      "⚠️ 121 - 페이지 2 수집 실패: HTTPConnectionPool(host='apis.data.go.kr', port=80): Read timed out. (read timeout=20)\n",
      "\n",
      "📍 지점 127 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 127 - 페이지 1 수집 완료\n",
      "✅ 127 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 129 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 129 - 페이지 1 수집 완료\n",
      "✅ 129 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 130 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 130 - 페이지 1 수집 완료\n",
      "✅ 130 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 131 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 131 - 페이지 1 수집 완료\n",
      "✅ 131 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 133 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 133 - 페이지 1 수집 완료\n",
      "✅ 133 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 135 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 135 - 페이지 1 수집 완료\n",
      "✅ 135 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 136 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 136 - 페이지 1 수집 완료\n",
      "✅ 136 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 137 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 137 - 페이지 1 수집 완료\n",
      "✅ 137 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 138 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 138 - 페이지 1 수집 완료\n",
      "✅ 138 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 140 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 140 - 페이지 1 수집 완료\n",
      "✅ 140 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 143 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 143 - 페이지 1 수집 완료\n",
      "✅ 143 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 146 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 146 - 페이지 1 수집 완료\n",
      "✅ 146 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 152 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 152 - 페이지 1 수집 완료\n",
      "✅ 152 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 155 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 155 - 페이지 1 수집 완료\n",
      "✅ 155 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 156 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 156 - 페이지 1 수집 완료\n",
      "✅ 156 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 159 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 159 - 페이지 1 수집 완료\n",
      "✅ 159 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 162 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 162 - 페이지 1 수집 완료\n",
      "✅ 162 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 165 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 165 - 페이지 1 수집 완료\n",
      "✅ 165 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 168 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 168 - 페이지 1 수집 완료\n",
      "✅ 168 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 169 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 169 - 페이지 1 수집 완료\n",
      "✅ 169 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 170 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 170 - 페이지 1 수집 완료\n",
      "⚠️ 170 - 페이지 2 수집 실패: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "📍 지점 172 데이터 수집 시작\n",
      "❌ 페이지 수 계산 실패 - 지점 172: HTTPConnectionPool(host='apis.data.go.kr', port=80): Read timed out. (read timeout=20)\n",
      "\n",
      "📍 지점 174 데이터 수집 시작\n",
      "❌ 페이지 수 계산 실패 - 지점 174: HTTPConnectionPool(host='apis.data.go.kr', port=80): Read timed out. (read timeout=20)\n",
      "\n",
      "📍 지점 177 데이터 수집 시작\n",
      "❌ 페이지 수 계산 실패 - 지점 177: HTTPConnectionPool(host='apis.data.go.kr', port=80): Read timed out. (read timeout=20)\n",
      "\n",
      "📍 지점 184 데이터 수집 시작\n",
      "❌ 페이지 수 계산 실패 - 지점 184: Expecting value: line 1 column 1 (char 0)\n",
      "\n",
      "📍 지점 185 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 185 - 페이지 1 수집 완료\n",
      "✅ 185 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 188 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "⚠️ 188 - 페이지 1 수집 실패: HTTPConnectionPool(host='apis.data.go.kr', port=80): Max retries exceeded with url: /1360000/AsosDalyInfoService/getWthrDataList?serviceKey=XT9kZ3aWiSgg3FkWJt%2Far8etCysXCBK%2FcbMh%2Bj0YI7B347LP9m88BBK7dG0DuwLuGuh2ShmTK9hqu00PvYHThg%3D%3D&pageNo=1&numOfRows=999&dataType=JSON&dataCd=ASOS&dateCd=DAY&startDt=20200101&endDt=20250527&stnIds=188 (Caused by ConnectTimeoutError(<urllib3.connection.HTTPConnection object at 0xffff36462510>, 'Connection to apis.data.go.kr timed out. (connect timeout=20)'))\n",
      "✅ 188 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 189 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 189 - 페이지 1 수집 완료\n",
      "✅ 189 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 192 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 192 - 페이지 1 수집 완료\n",
      "✅ 192 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 201 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 201 - 페이지 1 수집 완료\n",
      "✅ 201 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 202 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 202 - 페이지 1 수집 완료\n",
      "✅ 202 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 203 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 203 - 페이지 1 수집 완료\n",
      "✅ 203 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 211 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 211 - 페이지 1 수집 완료\n",
      "✅ 211 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 212 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 212 - 페이지 1 수집 완료\n",
      "✅ 212 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 216 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 216 - 페이지 1 수집 완료\n",
      "✅ 216 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 217 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 217 - 페이지 1 수집 완료\n",
      "✅ 217 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 221 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 221 - 페이지 1 수집 완료\n",
      "✅ 221 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 226 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 226 - 페이지 1 수집 완료\n",
      "✅ 226 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 232 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 232 - 페이지 1 수집 완료\n",
      "✅ 232 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 235 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 235 - 페이지 1 수집 완료\n",
      "✅ 235 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 236 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 236 - 페이지 1 수집 완료\n",
      "✅ 236 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 238 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 238 - 페이지 1 수집 완료\n",
      "✅ 238 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 239 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 239 - 페이지 1 수집 완료\n",
      "✅ 239 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 243 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 243 - 페이지 1 수집 완료\n",
      "✅ 243 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 244 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 244 - 페이지 1 수집 완료\n",
      "✅ 244 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 245 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 245 - 페이지 1 수집 완료\n",
      "✅ 245 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 247 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 247 - 페이지 1 수집 완료\n",
      "✅ 247 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 248 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 248 - 페이지 1 수집 완료\n",
      "✅ 248 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 251 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 251 - 페이지 1 수집 완료\n",
      "✅ 251 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 252 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 252 - 페이지 1 수집 완료\n",
      "✅ 252 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 253 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 253 - 페이지 1 수집 완료\n",
      "✅ 253 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 254 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 254 - 페이지 1 수집 완료\n",
      "✅ 254 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 255 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 255 - 페이지 1 수집 완료\n",
      "✅ 255 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 257 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 257 - 페이지 1 수집 완료\n",
      "✅ 257 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 258 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 258 - 페이지 1 수집 완료\n",
      "✅ 258 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 259 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 259 - 페이지 1 수집 완료\n",
      "✅ 259 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 260 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 260 - 페이지 1 수집 완료\n",
      "✅ 260 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 261 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 261 - 페이지 1 수집 완료\n",
      "✅ 261 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 262 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 262 - 페이지 1 수집 완료\n",
      "✅ 262 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 263 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 263 - 페이지 1 수집 완료\n",
      "✅ 263 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 264 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 264 - 페이지 1 수집 완료\n",
      "✅ 264 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 266 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 266 - 페이지 1 수집 완료\n",
      "✅ 266 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 268 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 268 - 페이지 1 수집 완료\n",
      "✅ 268 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 271 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 271 - 페이지 1 수집 완료\n",
      "✅ 271 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 272 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 272 - 페이지 1 수집 완료\n",
      "✅ 272 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 273 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 273 - 페이지 1 수집 완료\n",
      "✅ 273 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 276 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 276 - 페이지 1 수집 완료\n",
      "✅ 276 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 277 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 277 - 페이지 1 수집 완료\n",
      "✅ 277 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 278 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 278 - 페이지 1 수집 완료\n",
      "✅ 278 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 279 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 279 - 페이지 1 수집 완료\n",
      "✅ 279 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 281 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 281 - 페이지 1 수집 완료\n",
      "✅ 281 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 283 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 283 - 페이지 1 수집 완료\n",
      "✅ 283 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 284 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 284 - 페이지 1 수집 완료\n",
      "✅ 284 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 285 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 285 - 페이지 1 수집 완료\n",
      "✅ 285 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 288 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 288 - 페이지 1 수집 완료\n",
      "✅ 288 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 289 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 289 - 페이지 1 수집 완료\n",
      "✅ 289 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 294 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 294 - 페이지 1 수집 완료\n",
      "✅ 294 - 페이지 2 수집 완료\n",
      "\n",
      "📍 지점 295 데이터 수집 시작\n",
      "📄 총 페이지 수: 2\n",
      "✅ 295 - 페이지 1 수집 완료\n",
      "✅ 295 - 페이지 2 수집 완료\n",
      "\n",
      "✅ 전체 데이터 수집 완료. 총 샘플 수: 176676\n",
      "✅ 수집한 전체 데이터를 weather_fulldata.csv 파일로 저장했습니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# 어제 날짜를 YYYYMMDD 형식 문자열로 생성\n",
    "yesterday_str = (datetime.today() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "\n",
    "# 함수 호출 예시\n",
    "fetch_weather_data_to_s3_with_pagination(\n",
    "    start_date=\"20200101\",\n",
    "    end_date=yesterday_str,\n",
    "    station_csv_path=\"./weather_station_list.csv\",\n",
    "    s3_filename=\"weather_all_station.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354e867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 업로드된 파일 삭제\n",
    "s3_client.delete_object(Bucket=NCLOUD_STORAGE_BUCKET, Key=f\"{DATASETS_DIR}/weather_all_station.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
